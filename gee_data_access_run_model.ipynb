{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/am1235le/GY7720_Dissertation_209041686/blob/main/gee_data_access_run_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxBpW_qRpXS3"
      },
      "source": [
        "# Extract GEE Data into Google Storage Data Bucket\n",
        "\n",
        "Some sections of the following code that is used to access data from tfrecords was sourced and adapted from the code made available by Huot et al. (2022), which can be found under the following link:\n",
        "\n",
        "https://github.com/google-research/google-research/tree/master/simulation_research/next_day_wildfire_spread\n",
        "\n",
        "Huot F., Hu R. L., Goyal N., Sankar T., Ihme M. and Chen Y. F. 2022. Next Day Wildfire Spread: A Machine Learning Dataset to Predict Wildfire Spreading From Remote-Sensing Data. IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 1-13, 2022, Art no. 4412513, doi: 10.1109/TGRS.2022.3192974."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and load libraries"
      ],
      "metadata": {
        "id": "JfXx6iplUP8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install missing library\n",
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "wl9mpESsn8aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KagwjrHOpR1T"
      },
      "outputs": [],
      "source": [
        "# load libraries\n",
        "# base libraries\n",
        "import re\n",
        "from typing import Dict, List, Optional, Text, Tuple\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import shutil, sys\n",
        "import gzip\n",
        "import zipfile\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "\n",
        "# data analysis library\n",
        "import sklearn\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# required for plotting\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "\n",
        "# tensor flow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {tf.keras.__version__}\")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Reshape,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        "    Conv1D,\n",
        "    Conv2D,\n",
        "    Conv2DTranspose,\n",
        "    MaxPooling2D,\n",
        "    SimpleRNN,\n",
        "    LSTM,\n",
        "    GRU,\n",
        ")\n",
        "from tensorflow.keras.losses import (\n",
        "    Loss,\n",
        "    BinaryFocalCrossentropy)\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Drive and Google Storage Bucket"
      ],
      "metadata": {
        "id": "A4r16-4MVGd9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7zsRUy_pxHd"
      },
      "outputs": [],
      "source": [
        "# connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNa3cFsVp9IP"
      },
      "outputs": [],
      "source": [
        "# set working directory for data to be saved to\n",
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks/Dissertation/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXLlY6ekD33V"
      },
      "outputs": [],
      "source": [
        "# connect to project on Google Cloud containing Google storage bucket\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "project_id = 'project_name'\n",
        "!gcloud config set project {project_id}\n",
        "!gsutil ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVsNdnIBFNn3"
      },
      "outputs": [],
      "source": [
        "# copy data from Google Cloud bucket folder to local Google Drive\n",
        "bucket_name = 'bucket_name/folder_name'\n",
        "!gsutil -m cp -r gs://{bucket_name} /content/drive/My\\ Drive/Colab\\ Notebooks/Dissertation/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1Un9xLFp-x8"
      },
      "outputs": [],
      "source": [
        "# list data/folders in working directory\n",
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define features to be extracted from tfrecords and used in model"
      ],
      "metadata": {
        "id": "Z__EqbLqWPuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2cgMfGoABI8l"
      },
      "outputs": [],
      "source": [
        "# define list of features for extraction from tfrecord\n",
        "# training features\n",
        "INPUT_FEATURES = ['elevation',\n",
        "                  'populationdensity',\n",
        "                  'lulc', \n",
        "                  'pdsi',\n",
        "                  'pr',\n",
        "                  'erc',\n",
        "                  'SPFH',\n",
        "                  'WDIR',\n",
        "                  'WIND',\n",
        "                  'GUST',\n",
        "                  'UGRD',\n",
        "                  'VGRD',\n",
        "                  'TMP',\n",
        "                  'ndvid',\n",
        "                  'ndii',\n",
        "                  'nbr',\n",
        "                  'dnbr',\n",
        "                  'PrevFireMask'\n",
        "                  ]\n",
        "# target labels\n",
        "OUTPUT_FEATURES = ['FireMask', ]\n",
        "\n",
        "# Data statistics for each rescaling each variable\n",
        "# the statistics are ordered in the form:\n",
        "# (min_clip, max_clip, mean, std)\n",
        "DATA_STATS = {\n",
        "    # Elevation m\n",
        "    'elevation': (-50, 6500, 1400, 280),\n",
        "    # Population p/sqkm\n",
        "    'populationdensity': (0, 810694, 7, 88),\n",
        "    # Urban LULC\n",
        "    'lulc': (0,1,0.5,0.5),\n",
        "    # Palmer Drought Severity Index no units\n",
        "    'pdsi': (-15, 15, -2, 0.6),\n",
        "    # Precipitation mm, daily total\n",
        "    'pr': (0, 100, 0.04, 0.06),\n",
        "    # NFDRS fire danger index Energy release component\n",
        "    'erc': (0.0, 131.85, 76.68, 2.25),\n",
        "    # Specific humidity\n",
        "    'SPFH': (0, 0.02, 0.01, 0.01),\n",
        "    # Wind direction\n",
        "    'WDIR': (0, 360, 212, 20),\n",
        "    # Wind speed\n",
        "    'WIND': (0, 42.46, 3.1, 0.2),\n",
        "    # Wind gust\n",
        "    'GUST': (0, 58.02, 10, 1),\n",
        "    # Wind U\n",
        "    'UGRD': (-32.93, 34.04, 0, 33),\n",
        "    # Wind V\n",
        "    'VGRD': (-28.44, 39.21, 5, 35),\n",
        "    # Temperature\n",
        "    'TMP': (-43.2, 43.73, 0, 43),\n",
        "    # Normalised Difference Vegetation Index\n",
        "    'ndvid': (-1, 1, 0, 1),\n",
        "    # Normalised Difference Infrared Index\n",
        "    'ndii': (-1, 1, 0, 1),\n",
        "    # Normalised Burn Ratio\n",
        "    'nbr': (-1, 1, 0, 1),\n",
        "    # Difference Normalised Burn Ratio\n",
        "    'dnbr': (-2, 2, 0, 2),\n",
        "    # FireMasks.\n",
        "    'PrevFireMask': (0, 1, 0.5, 0.5),\n",
        "    'FireMask': (0, 1, 0.5, 0.5)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AedQ9BgOfd_3"
      },
      "outputs": [],
      "source": [
        "# list defined date feature statistics\n",
        "print(DATA_STATS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq4UVk6v5qZQ"
      },
      "source": [
        "## Define function to extract tfrecord data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5TRI2uRZ4vSU"
      },
      "outputs": [],
      "source": [
        "# define functions to extract data from tfrecords\n",
        "# sourced from Huot et al. (2022)\n",
        "\n",
        "# function to randomly crop input and output images\n",
        "\"\"\"Library of common functions used in deep learning neural networks.\n",
        "\"\"\"\n",
        "def random_crop_input_and_output_images(\n",
        "    input_img: tf.Tensor,\n",
        "    output_img: tf.Tensor,\n",
        "    sample_size: int,\n",
        "    num_in_channels: int,\n",
        "    num_out_channels: int,\n",
        ") -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "  \"\"\"Randomly axis-align crop input and output image tensors.\n",
        "\n",
        "  Args:\n",
        "    input_img: Tensor with dimensions HWC.\n",
        "    output_img: Tensor with dimensions HWC.\n",
        "    sample_size: Side length (square) to crop to.\n",
        "    num_in_channels: Number of channels in `input_img`.\n",
        "    num_out_channels: Number of channels in `output_img`.\n",
        "  Returns:\n",
        "    input_img: Tensor with dimensions HWC.\n",
        "    output_img: Tensor with dimensions HWC.\n",
        "  \"\"\"\n",
        "  combined = tf.concat([input_img, output_img], axis=2)\n",
        "  combined = tf.image.random_crop(\n",
        "      combined,\n",
        "      [sample_size, sample_size, num_in_channels + num_out_channels])\n",
        "  input_img = combined[:, :, 0:num_in_channels]\n",
        "  output_img = combined[:, :, -num_out_channels:]\n",
        "  return input_img, output_img\n",
        "\n",
        "# function to crop input and output images; from center of image\n",
        "def center_crop_input_and_output_images(\n",
        "    input_img: tf.Tensor,\n",
        "    output_img: tf.Tensor,\n",
        "    sample_size: int,\n",
        ") -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "  \"\"\"Calls `tf.image.central_crop` on input and output image tensors.\n",
        "\n",
        "  Args:\n",
        "    input_img: Tensor with dimensions HWC.\n",
        "    output_img: Tensor with dimensions HWC.\n",
        "    sample_size: Side length (square) to crop to.\n",
        "  Returns:\n",
        "    input_img: Tensor with dimensions HWC.\n",
        "    output_img: Tensor with dimensions HWC.\n",
        "  \"\"\"\n",
        "  central_fraction = sample_size / input_img.shape[0]\n",
        "  input_img = tf.image.central_crop(input_img, central_fraction)\n",
        "  output_img = tf.image.central_crop(output_img, central_fraction)\n",
        "  return input_img, output_img\n",
        "\"\"\"Dataset reader for Earth Engine data.\"\"\"\n",
        "\n",
        "# extract data keys\n",
        "def _get_base_key(key: Text) -> Text:\n",
        "  \"\"\"Extracts the base key from the provided key.\n",
        "\n",
        "  Earth Engine exports TFRecords containing each data variable with its\n",
        "  corresponding variable name. In the case of time sequences, the name of the\n",
        "  data variable is of the form 'variable_1', 'variable_2', ..., 'variable_n',\n",
        "  where 'variable' is the name of the variable, and n the number of elements\n",
        "  in the time sequence. Extracting the base key ensures that each step of the\n",
        "  time sequence goes through the same normalization steps.\n",
        "  The base key obeys the following naming pattern: '[a-zA-Z]+'\n",
        "  For instance, for an input key 'variable_1', this function returns 'variable'.\n",
        "  For an input key 'variable', this function simply returns 'variable'.\n",
        "\n",
        "  Args:\n",
        "    key: Input key.\n",
        "\n",
        "  Returns:\n",
        "    The corresponding base key.\n",
        "\n",
        "  Raises:\n",
        "    ValueError when `key` does not match the expected pattern.\n",
        "  \"\"\"\n",
        "  match = re.match(r'[a-zA-Z]+', key)\n",
        "  if match:\n",
        "    return match.group(0)\n",
        "  raise ValueError(\n",
        "      f'The provided key does not match the expected pattern: {key}')\n",
        "\n",
        "# function to clip and rescale image data values based on statistics\n",
        "def _clip_and_rescale(inputs: tf.Tensor, key: Text) -> tf.Tensor:\n",
        "  \"\"\"Clips and rescales inputs with the stats corresponding to `key`.\n",
        "\n",
        "  Args:\n",
        "    inputs: Inputs to clip and rescale.\n",
        "    key: Key describing the inputs.\n",
        "\n",
        "  Returns:\n",
        "    Clipped and rescaled input.\n",
        "\n",
        "  Raises:\n",
        "    ValueError if there are no data statistics available for `key`.\n",
        "  \"\"\"\n",
        "  base_key = _get_base_key(key)\n",
        "  if base_key not in DATA_STATS:\n",
        "    raise ValueError(\n",
        "        'No data statistics available for the requested key: {}.'.format(key))\n",
        "  min_val, max_val, _, _ = DATA_STATS[base_key]\n",
        "  inputs = tf.clip_by_value(inputs, min_val, max_val)\n",
        "  return tf.math.divide_no_nan((inputs - min_val), (max_val - min_val))\n",
        "\n",
        "# function to clip and normalize image data values based on statistics\n",
        "def _clip_and_normalize(inputs: tf.Tensor, key: Text) -> tf.Tensor:\n",
        "  \"\"\"Clips and normalizes inputs with the stats corresponding to `key`.\n",
        "\n",
        "  Args:\n",
        "    inputs: Inputs to clip and normalize.\n",
        "    key: Key describing the inputs.\n",
        "\n",
        "  Returns:\n",
        "    Clipped and normalized input.\n",
        "\n",
        "  Raises:\n",
        "    ValueError if there are no data statistics available for `key`.\n",
        "  \"\"\"\n",
        "  base_key = _get_base_key(key)\n",
        "  if base_key not in DATA_STATS:\n",
        "    raise ValueError(\n",
        "        'No data statistics available for the requested key: {}.'.format(key))\n",
        "  min_val, max_val, mean, std = DATA_STATS[base_key]\n",
        "  inputs = tf.clip_by_value(inputs, min_val, max_val)\n",
        "  inputs = inputs - mean\n",
        "  return tf.math.divide_no_nan(inputs, std)\n",
        "\n",
        "# define data feature dictionary\n",
        "def _get_features_dict(\n",
        "    sample_size: int,\n",
        "    features: List[Text],\n",
        ") -> Dict[Text, tf.io.FixedLenFeature]:\n",
        "  \"\"\"Creates a features dictionary for TensorFlow IO.\n",
        "\n",
        "  Args:\n",
        "    sample_size: Size of the input tiles (square).\n",
        "    features: List of feature names.\n",
        "\n",
        "  Returns:\n",
        "    A features dictionary for TensorFlow IO.\n",
        "  \"\"\"\n",
        "  sample_shape = [sample_size, sample_size]\n",
        "  features = set(features)\n",
        "  columns = [\n",
        "      tf.io.FixedLenFeature(shape=sample_shape, dtype=tf.float32)\n",
        "      for _ in features\n",
        "  ]\n",
        "  return dict(zip(features, columns))\n",
        "\n",
        "# function to read and format data as defined\n",
        "def _parse_fn(\n",
        "    example_proto: tf.train.Example, data_size: int, sample_size: int,\n",
        "    num_in_channels: int, clip_and_normalize: bool,\n",
        "    clip_and_rescale: bool, random_crop: bool, center_crop: bool,\n",
        ") -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "  \"\"\"Reads a serialized example.\n",
        "\n",
        "  Args:\n",
        "    example_proto: A TensorFlow example protobuf.\n",
        "    data_size: Size of tiles (square) as read from input files.\n",
        "    sample_size: Size the tiles (square) when input into the model.\n",
        "    num_in_channels: Number of input channels.\n",
        "    clip_and_normalize: True if the data should be clipped and normalized.\n",
        "    clip_and_rescale: True if the data should be clipped and rescaled.\n",
        "    random_crop: True if the data should be randomly cropped.\n",
        "    center_crop: True if the data should be cropped in the center.\n",
        "\n",
        "  Returns:\n",
        "    (input_img, output_img) tuple of inputs and outputs to the ML model.\n",
        "  \"\"\"\n",
        "  if (random_crop and center_crop):\n",
        "    raise ValueError('Cannot have both random_crop and center_crop be True')\n",
        "  input_features, output_features = INPUT_FEATURES, OUTPUT_FEATURES\n",
        "  feature_names = input_features + output_features\n",
        "  features_dict = _get_features_dict(data_size, feature_names)\n",
        "  features = tf.io.parse_single_example(example_proto, features_dict)\n",
        "\n",
        "  if clip_and_normalize:\n",
        "    inputs_list = [\n",
        "        _clip_and_normalize(features.get(key), key) for key in input_features\n",
        "    ]\n",
        "  elif clip_and_rescale:\n",
        "    inputs_list = [\n",
        "        _clip_and_rescale(features.get(key), key) for key in input_features\n",
        "    ]\n",
        "  else:\n",
        "    inputs_list = [features.get(key) for key in input_features]\n",
        "\n",
        "  inputs_stacked = tf.stack(inputs_list, axis=0)\n",
        "  input_img = tf.transpose(inputs_stacked, [1, 2, 0])\n",
        "\n",
        "  outputs_list = [features.get(key) for key in output_features]\n",
        "  assert outputs_list, 'outputs_list should not be empty'\n",
        "  outputs_stacked = tf.stack(outputs_list, axis=0)\n",
        "\n",
        "  outputs_stacked_shape = outputs_stacked.get_shape().as_list()\n",
        "  assert len(outputs_stacked.shape) == 3, ('outputs_stacked should be rank 3'\n",
        "                                            'but dimensions of outputs_stacked'\n",
        "                                            f' are {outputs_stacked_shape}')\n",
        "  output_img = tf.transpose(outputs_stacked, [1, 2, 0])\n",
        "\n",
        "  if random_crop:\n",
        "    input_img, output_img = random_crop_input_and_output_images(\n",
        "        input_img, output_img, sample_size, num_in_channels, 1)\n",
        "  if center_crop:\n",
        "    input_img, output_img = center_crop_input_and_output_images(\n",
        "        input_img, output_img, sample_size)\n",
        "  return input_img, output_img\n",
        "\n",
        "# consolidated function to extract tfrecord data\n",
        "def get_dataset(file_pattern: Text, data_size: int, sample_size: int,\n",
        "                batch_size: int, num_in_channels: int, compression_type: Text,\n",
        "                clip_and_normalize: bool, clip_and_rescale: bool,\n",
        "                random_crop: bool, center_crop: bool) -> tf.data.Dataset:\n",
        "  \"\"\"Gets the dataset from the file pattern.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: Input file pattern.\n",
        "    data_size: Size of tiles (square) as read from input files.\n",
        "    sample_size: Size the tiles (square) when input into the model.\n",
        "    batch_size: Batch size.\n",
        "    num_in_channels: Number of input channels.\n",
        "    compression_type: Type of compression used for the input files.\n",
        "    clip_and_normalize: True if the data should be clipped and normalized, False\n",
        "      otherwise.\n",
        "    clip_and_rescale: True if the data should be clipped and rescaled, False\n",
        "      otherwise.\n",
        "    random_crop: True if the data should be randomly cropped.\n",
        "    center_crop: True if the data shoulde be cropped in the center.\n",
        "\n",
        "  Returns:\n",
        "    A TensorFlow dataset loaded from the input file pattern, with features\n",
        "    described in the constants, and with the shapes determined from the input\n",
        "    parameters to this function.\n",
        "  \"\"\"\n",
        "  if (clip_and_normalize and clip_and_rescale):\n",
        "    raise ValueError('Cannot have both normalize and rescale.')\n",
        "  dataset = tf.data.Dataset.list_files(file_pattern)\n",
        "  dataset = dataset.interleave(\n",
        "      lambda x: tf.data.TFRecordDataset(x, compression_type=compression_type),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  dataset = dataset.map(\n",
        "      lambda x: _parse_fn(  # pylint: disable=g-long-lambda\n",
        "          x, data_size, sample_size, num_in_channels, clip_and_normalize,\n",
        "          clip_and_rescale, random_crop, center_crop),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uEkWDq9cxsi"
      },
      "source": [
        "## Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nZ_Xntm4l2L"
      },
      "outputs": [],
      "source": [
        "# define filename pattern to identify train, eval, test files\n",
        "file_pattern = 'train*'\n",
        "file_pattern_eval = 'eval*'\n",
        "file_pattern_test = 'test*'\n",
        "print(file_pattern)\n",
        "print(file_pattern_eval)\n",
        "print(file_pattern_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OblvPiw5-Kq_"
      },
      "outputs": [],
      "source": [
        "# specify folder containing data downloaded from Google storage bucket\n",
        "downloaddir = \"/content/drive/My Drive/Colab Notebooks/Dissertation/data/folder_name\"\n",
        "os.chdir(downloaddir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpH5eCBqCJfq"
      },
      "outputs": [],
      "source": [
        "# list files in download folder\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4lA3lFt36nXL"
      },
      "outputs": [],
      "source": [
        "# call function to extract data from files in download folder\n",
        "# data_size = size of tile extracted from tfrecord\n",
        "# sample_size = size of tile for model training\n",
        "# batch_size = training data sample size to extract\n",
        "# num_in_channels = number of training features to extract\n",
        "# select EITHER clip_and_normalize=True OR clip_and_rescale=True\n",
        "# select EITHER random_crop=False OR center_crop=True\n",
        "\n",
        "# training dataset\n",
        "dataset = get_dataset(\n",
        "      file_pattern,\n",
        "      data_size=128,\n",
        "      sample_size=32,\n",
        "      batch_size=2000,\n",
        "      num_in_channels=18,\n",
        "      compression_type=\"GZIP\",\n",
        "      clip_and_normalize=False,\n",
        "      clip_and_rescale=True,\n",
        "      random_crop=False,\n",
        "      center_crop=True)\n",
        "\n",
        "# evaluation dataset\n",
        "dataset_eval = get_dataset(\n",
        "      file_pattern_eval,\n",
        "      data_size=128,\n",
        "      sample_size=32,\n",
        "      batch_size=2000,\n",
        "      num_in_channels=18,\n",
        "      compression_type=\"GZIP\",\n",
        "      clip_and_normalize=False,\n",
        "      clip_and_rescale=True,\n",
        "      random_crop=False,\n",
        "      center_crop=True)\n",
        "\n",
        "# testing dataset\n",
        "dataset_test = get_dataset(\n",
        "      file_pattern_test,\n",
        "      data_size=128,\n",
        "      sample_size=32,\n",
        "      batch_size=400,\n",
        "      num_in_channels=18,\n",
        "      compression_type=\"GZIP\",\n",
        "      clip_and_normalize=False,\n",
        "      clip_and_rescale=True,\n",
        "      random_crop=False,\n",
        "      center_crop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cazaDCsphxCw"
      },
      "source": [
        "## Extract Inputs and Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract inputs and labels from extracted data"
      ],
      "metadata": {
        "id": "311IhFgAXuLK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9zT55W_8CXDH"
      },
      "outputs": [],
      "source": [
        "inputs, labels = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "a8KLB2GkfQw7"
      },
      "outputs": [],
      "source": [
        "inputs_eval, labels_eval = next(iter(dataset_eval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UChdzqwA2UwE"
      },
      "outputs": [],
      "source": [
        "inputs_test, labels_test = next(iter(dataset_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuJ8YGLP2Kxk"
      },
      "source": [
        "### Extract statistics for extracted data features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFe_DCxCytZh"
      },
      "outputs": [],
      "source": [
        "# extract summary of values per band in tensors\n",
        "tsz = inputs.shape[1]*inputs.shape[2]\n",
        "# calculate dataset stats\n",
        "for varx in range(0,inputs.shape[-1]):\n",
        "  mi = None\n",
        "  mx = None\n",
        "  mn = None\n",
        "  sd = None\n",
        "  for x in range(0,inputs.shape[0]):\n",
        "    if mi == None:\n",
        "      mi = min(np.unique(inputs[x, :, :, varx]))\n",
        "      mx = max(np.unique(inputs[x, :, :, varx]))\n",
        "      mn = np.mean(inputs[x, :, :, varx])\n",
        "      sd = np.std(inputs[x, :, :, varx])**2\n",
        "    else:\n",
        "      if (min(np.unique(inputs[x, :, :, varx])) < mi):\n",
        "        mi = min(np.unique(inputs[x, :, :, varx]))\n",
        "      if (max(np.unique(inputs[x, :, :, varx])) > mx):\n",
        "        mx = max(np.unique(inputs[x, :, :, varx]))\n",
        "      mn = mn + np.mean(inputs[x, :, :, varx])\n",
        "      sd = sd + (np.std(inputs[x, :, :, varx])**2)\n",
        "  print(f\"Min {varx} - {INPUT_FEATURES[varx]}: {mi}\")\n",
        "  print(f\"Max {varx} - {INPUT_FEATURES[varx]}: {mx}\")\n",
        "  print(f\"Mean {varx} - {INPUT_FEATURES[varx]}: {mn/inputs.shape[0]}\")\n",
        "  print(f\"Std {varx} - {INPUT_FEATURES[varx]}: {np.sqrt(sd/inputs.shape[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrSN7Ooy7po4"
      },
      "source": [
        "## Mapping Sample Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Bbfe4xPfCn85"
      },
      "outputs": [],
      "source": [
        "# define feature names and plot parameters\n",
        "# adapted from Huot et al. (2022)\n",
        "TITLES = [\n",
        "  'Elevation',\n",
        "  'Population\\ndensity',\n",
        "  'Urban',\n",
        "  'Drought',\n",
        "  'Precip',\n",
        "  'Energy\\nrelease\\ncomponent',\n",
        "  'Humidity',\n",
        "  'Wind\\ndirection',\n",
        "  'Wind\\nvelocity',\n",
        "  'Wind\\ngust',\n",
        "  'Wind\\nU',\n",
        "  'Wind\\nV',\n",
        "  'Temp',\n",
        "  'NDVI',\n",
        "  'NDII',\n",
        "  'NBR',\n",
        "  'dNBR',\n",
        "  'Previous\\nfire\\nmask',\n",
        "  'Fire\\nmask'\n",
        "]\n",
        "\n",
        "n_rows = 4\n",
        "n_features = inputs.shape[3]\n",
        "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
        "BOUNDS = [-1, -0.1, 0.001, 1]\n",
        "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpuHU6uwDIQY"
      },
      "outputs": [],
      "source": [
        "# plot random sample of images\n",
        "# adapted from Huot et al. (2022)\n",
        "fig = plt.figure(figsize=(20,8))\n",
        "\n",
        "nrows = random.sample(range(1, 250), n_rows)\n",
        "\n",
        "for i in range(n_rows):\n",
        "  k = nrows[i]\n",
        "  for j in range(n_features + 1):\n",
        "    plt.subplot(n_rows, n_features + 1, i * (n_features + 1) + j + 1)\n",
        "    if i == 0:\n",
        "      plt.title(TITLES[j], fontsize=13)\n",
        "    if j < n_features - 1:\n",
        "      plt.imshow(inputs[k, :, :, j], cmap='viridis')\n",
        "    if j == n_features - 1:\n",
        "      plt.imshow(inputs[k, :, :, -1], cmap=CMAP, norm=NORM)\n",
        "    if j == n_features:\n",
        "      plt.imshow(labels[k, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    plt.axis('off')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8d62HZLhvdz"
      },
      "source": [
        "## U-Net model setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define base component model blocks"
      ],
      "metadata": {
        "id": "loCr0TrueFZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-O2cddmMgad0"
      },
      "outputs": [],
      "source": [
        "# define double convolutional block\n",
        "def double_conv2d_block(x, n_filters):\n",
        "  # Conv2D \n",
        "  x = tf.keras.layers.Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding = \"same\", kernel_initializer = \"he_normal\")(x)\n",
        "  # Conv2D \n",
        "  x = tf.keras.layers.Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding = \"same\", kernel_initializer = \"he_normal\")(x)\n",
        "  return x\n",
        "\n",
        "# define downsampling block\n",
        "# includes double conv2d block, maxpool and dropout layers\n",
        "def downsample_block(x, n_filters):\n",
        "  # Conv2D \n",
        "  f = double_conv2d_block(x, n_filters)\n",
        "  # downsample\n",
        "  p = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(f)\n",
        "  # dropout\n",
        "  p = tf.keras.layers.Dropout(0.3)(p)\n",
        "  return f, p\n",
        "\n",
        "# define upsampling block\n",
        "# includes transpose, concatenation and dropout layers followed by double conv2d block\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "  # upsample\n",
        "  x = tf.keras.layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "  # concatenate\n",
        "  x = tf.keras.layers.concatenate([x, conv_features])\n",
        "  # dropout\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "  # Conv2D \n",
        "  x = double_conv2d_block(x, n_filters)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KrgPeRTA1us"
      },
      "source": [
        "### Define 2 layer U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "71jLiPzC8-FA"
      },
      "outputs": [],
      "source": [
        "# define 2 layer U-NET model\n",
        "def build_unet2_model(nfilters=32):\n",
        "\n",
        "  input_shape = inputs.shape\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=input_shape[1:])\n",
        "  \n",
        "  # downsample\n",
        "  d1, do1 = downsample_block(inp, nfilters)\n",
        "  # downsample\n",
        "  d2, do2 = downsample_block(do1, (nfilters*2))\n",
        "  # bottleneck\n",
        "  bottleneck = double_conv2d_block(do2, (nfilters*4))\n",
        "  # upsample\n",
        "  u1 = upsample_block(bottleneck, d2, (nfilters*2))\n",
        "  # upsample\n",
        "  u2 = upsample_block(u1, d1, nfilters)\n",
        "\n",
        "  # outputs\n",
        "  outputs = tf.keras.layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u2)\n",
        "\n",
        "  # unet model with Keras Functional API\n",
        "  unet_model = tf.keras.Model(inp, outputs, name=\"U-Net\")\n",
        "  \n",
        "  return unet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDgdi2ZSA7rt"
      },
      "source": [
        "### Define 3 layer U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "veIJ6YSig0ys"
      },
      "outputs": [],
      "source": [
        "# define 3 layer U-NET model\n",
        "def build_unet3_model(nfilters=32):\n",
        "\n",
        "  input_shape = inputs.shape\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=input_shape[1:])\n",
        "  \n",
        "  # downsample\n",
        "  d1, do1 = downsample_block(inp, nfilters)\n",
        "  # downsample\n",
        "  d2, do2 = downsample_block(do1, (nfilters*2))\n",
        "  # downsample\n",
        "  d3, do3 = downsample_block(do2, (nfilters*4))\n",
        "  # bottleneck\n",
        "  bottleneck = double_conv2d_block(do3, (nfilters*8))\n",
        "  # upsample\n",
        "  u1 = upsample_block(bottleneck, d3, (nfilters*4))\n",
        "  # upsample\n",
        "  u2 = upsample_block(u1, d2, (nfilters*2))\n",
        "  # upsample\n",
        "  u3 = upsample_block(u2, d1, nfilters)\n",
        "\n",
        "  # outputs\n",
        "  outputs = tf.keras.layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u3)\n",
        "\n",
        "  # unet model with Keras Functional API\n",
        "  unet_model = tf.keras.Model(inp, outputs, name=\"U-Net\")\n",
        "  \n",
        "  return unet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M75_ERkwBABl"
      },
      "source": [
        "### Define 4 layer U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NLmSbJ3J8Olz"
      },
      "outputs": [],
      "source": [
        "# define 4 layer U-NET model\n",
        "def build_unet4_model(nfilters=32):\n",
        "\n",
        "  input_shape = inputs.shape\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=input_shape[1:])\n",
        "  \n",
        "  # downsample\n",
        "  d1, do1 = downsample_block(inp, nfilters)\n",
        "  # downsample\n",
        "  d2, do2 = downsample_block(do1, (nfilters*2))\n",
        "  # downsample\n",
        "  d3, do3 = downsample_block(do2, (nfilters*4))\n",
        "  # downsample\n",
        "  d4, do4 = downsample_block(do3, (nfilters*8))\n",
        "  # bottleneck\n",
        "  bottleneck = double_conv2d_block(do4, (nfilters*16))\n",
        "  # upsample\n",
        "  u1 = upsample_block(bottleneck, d4, (nfilters*8))\n",
        "  # upsample\n",
        "  u2 = upsample_block(u1, d3, (nfilters*4))\n",
        "  # upsample\n",
        "  u3 = upsample_block(u2, d2, (nfilters*2))\n",
        "  # upsample\n",
        "  u4 = upsample_block(u3, d1, nfilters)\n",
        "\n",
        "  # outputs\n",
        "  outputs = tf.keras.layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u4)\n",
        "\n",
        "  # unet model with Keras Functional API\n",
        "  unet_model = tf.keras.Model(inp, outputs, name=\"U-Net\")\n",
        "  \n",
        "  return unet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZBEN7aaGrDe"
      },
      "source": [
        "### Define custom metrics to evaluate model performance\n",
        "\n",
        "The following code cell was sourced from the following link:\n",
        "\n",
        "https://gist.github.com/arnaldog12/5f2728f229a8bd3b4673b72786913252"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zuJZE0ExDJSg"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI8QujVuhptU"
      },
      "source": [
        "## Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Iy0ZyC2riyyZ"
      },
      "outputs": [],
      "source": [
        "# define model based on required number of layers and filters\n",
        "unet_model = build_unet3_model(nfilters=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBZL2_wynXzF"
      },
      "outputs": [],
      "source": [
        "# print model summary\n",
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zubzGwH-i3XG"
      },
      "outputs": [],
      "source": [
        "# plot model summary\n",
        "tf.keras.utils.plot_model(unet_model, rankdir='LR', show_shapes=False, show_layer_activations=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define optimisation function and learning rate\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "C_h4IKx6ikmB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GQwBlHh2jcls"
      },
      "outputs": [],
      "source": [
        "# compile model including optimizer, loss function and required metrics\n",
        "unet_model.compile(optimizer=opt,\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\",\n",
        "                           tf.keras.metrics.AUC(name='auc'),\n",
        "                           f1_m,\n",
        "                           precision_m,\n",
        "                           recall_m,\n",
        "                           tf.keras.metrics.BinaryIoU(target_class_ids=[1],threshold=0.5,name='iou')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJnN44nujezG"
      },
      "outputs": [],
      "source": [
        "# train model for defined number of epochs\n",
        "# include in training validation split of 20%\n",
        "model_history = unet_model.fit(inputs, labels,\n",
        "                               epochs=40,\n",
        "                               validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate trained model and plot metrics"
      ],
      "metadata": {
        "id": "hGhJkeH-jq4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1e3d7ikF6IEY"
      },
      "outputs": [],
      "source": [
        "# save trained model to working folder for future evaluation\n",
        "save_model_as = \"model_name\"\n",
        "unet_model.save(save_model_as+\".h5\",save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWKtyq3FwZ7U"
      },
      "outputs": [],
      "source": [
        "# extract metrics values for the trained network using the evaluation dataset\n",
        "evalscores = unet_model.evaluate(inputs_eval, labels_eval, verbose=0)\n",
        "\n",
        "print(f\"Evaluation Loss: {evalscores[0]:.05f}\")\n",
        "print(f\"Evaluation Accuracy: {evalscores[1]:.05f}\")\n",
        "print(f\"Evaluation AUC: {evalscores[2]:.05f}\")\n",
        "print(f\"Evaluation F1: {evalscores[3]:.05f}\")\n",
        "print(f\"Evaluation Precision: {evalscores[4]:.05f}\")\n",
        "print(f\"Evaluation Recall: {evalscores[5]:.05f}\")\n",
        "print(f\"Evaluation IoU: {evalscores[6]:.05f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define eval metrics df to save evaluated metrics\n",
        "column_names = [\"Model\", \"Dataset\", \"Loss\", \"Accuracy\",\n",
        "                \"AUC\", \"F1\", \"Precision\", \"Recall\", \"IoU\"]\n",
        "\n",
        "evalmetrics = pd.DataFrame(columns = column_names)"
      ],
      "metadata": {
        "id": "qc6nshOVsGHK"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model name to associate with results\n",
        "model_settings = \"model_name\"\n",
        "# write evaluation metrics to df\n",
        "eval_new_row = {\"Model\": model_settings,\n",
        "                \"Dataset\": downloaddir.split(\"/\")[7],\n",
        "                \"Loss\": evalscores[0], \"Accuracy\": evalscores[1],\n",
        "                \"AUC\": evalscores[2], \"F1\": evalscores[3],\n",
        "                \"Precision\": evalscores[4], \"Recall\": evalscores[5],\n",
        "                \"IoU\": evalscores[6]}\n",
        "evalmetrics = evalmetrics.append(eval_new_row, ignore_index=True)\n",
        "# print df metrics\n",
        "print(evalmetrics)"
      ],
      "metadata": {
        "id": "NgZ5X5MUsHv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export evalmetrics df to csv when all required analyses complete\n",
        "test_csv_file = os.path.join(downloaddir,\"output.csv\")\n",
        "with open(test_csv_file, mode='w') as f:\n",
        "  evalmetrics.to_csv(f)"
      ],
      "metadata": {
        "id": "ZbiWr2BUJFR1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot model training history\n",
        "# define plot attributes\n",
        "fig = plt.figure()\n",
        "ax = plt.subplot(111)\n",
        "ax.set_ylabel('Metric Value')\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylim([0.1, 1])\n",
        "ax.grid(color='grey', linestyle='-.', linewidth=0.5)\n",
        "\n",
        "# plot history\n",
        "ax.plot(model_history.history['auc'],color='red',label='Train-AUC')\n",
        "ax.plot(model_history.history['val_auc'],color='darkred',label='Eval-AUC')\n",
        "ax.plot(model_history.history['f1_m'],color='yellow',label='Train-F1')\n",
        "ax.plot(model_history.history['val_f1_m'],color='darkorange',label='Eval-F1')\n",
        "ax.plot(model_history.history['iou'],color='blue',label='Train-IoU')\n",
        "ax.plot(model_history.history['val_iou'],color='darkblue',label='Eval-IoU')\n",
        "\n",
        "# shrink axis by 20% to place legend outside plot extent\n",
        "box = ax.get_position()\n",
        "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "\n",
        "# place legend to the right of the plot\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O7ckLBcXxdH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write model training history to df\n",
        "hist_df = pd.DataFrame(model_history.history) "
      ],
      "metadata": {
        "id": "Xb3mpB7msZrL"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saved model history to csv for future analysis\n",
        "hist_csv_file = os.path.join(downloaddir,save_model_as+\".csv\")\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "  hist_df.to_csv(f)"
      ],
      "metadata": {
        "id": "sa-UDKLDsaoH"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load saved model for testing against loaded dataset"
      ],
      "metadata": {
        "id": "kGIaQsqyNkBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define folder name for saved model and model name\n",
        "savedmodeldir = \"/content/drive/My Drive/Colab Notebooks/Dissertation/data/folder_name\"\n",
        "os.chdir(savedmodeldir)\n",
        "# load saved model from source directory\n",
        "model_to_load = \"model_name.h5\"\n",
        "unet_model_open = keras.models.load_model(model_to_load,\n",
        "                                          custom_objects={\"f1_m\": f1_m,\n",
        "                                                          \"recall_m\": recall_m,\n",
        "                                                          \"precision_m\": precision_m})"
      ],
      "metadata": {
        "id": "9-dFrfZH3ZsK"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define eval metrics df to save evaluated metrics\n",
        "column_names = [\"Model\", \"Dataset\", \"Loss\", \"Accuracy\",\n",
        "                \"AUC\", \"F1\", \"Precision\", \"Recall\", \"IoU\"]\n",
        "\n",
        "evalmetrics = pd.DataFrame(columns = column_names)"
      ],
      "metadata": {
        "id": "YsUCfZj-Y4EU"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIzkYv1YWQek"
      },
      "outputs": [],
      "source": [
        "# check summary of loaded model\n",
        "unet_model_open.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsBxsnnnDAWz"
      },
      "outputs": [],
      "source": [
        "# evaluate loaded model based on current dataset\n",
        "evalscores = unet_model_open.evaluate(inputs_eval, labels_eval, verbose=0)\n",
        "\n",
        "print(f\"Evaluation Loss: {evalscores[0]:.05f}\")\n",
        "print(f\"Evaluation Accuracy: {evalscores[1]:.05f}\")\n",
        "print(f\"Evaluation AUC: {evalscores[2]:.05f}\")\n",
        "print(f\"Evaluation F1: {evalscores[3]:.05f}\")\n",
        "print(f\"Evaluation Precision: {evalscores[4]:.05f}\")\n",
        "print(f\"Evaluation Recall: {evalscores[5]:.05f}\")\n",
        "print(f\"Evaluation IoU: {evalscores[6]:.05f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write evaluation metrics to df\n",
        "eval_new_row = {\"Model\": model_to_load,\n",
        "                \"Dataset\": downloaddir.split(\"/\")[7],\n",
        "                \"Loss\": evalscores[0], \"Accuracy\": evalscores[1],\n",
        "                \"AUC\": evalscores[2], \"F1\": evalscores[3],\n",
        "                \"Precision\": evalscores[4], \"Recall\": evalscores[5],\n",
        "                \"IoU\": evalscores[6]}\n",
        "evalmetrics = evalmetrics.append(eval_new_row, ignore_index=True)\n",
        "print(evalmetrics)"
      ],
      "metadata": {
        "id": "FCQerbu3ZAuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export evalmetrics df to csv when all required analyses complete\n",
        "pred_csv_file = os.path.join(downloaddir,\"eval_output.csv\")\n",
        "with open(pred_csv_file, mode='w') as f:\n",
        "  evalmetrics.to_csv(f)"
      ],
      "metadata": {
        "id": "SNcV68R8TtvO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HstRZ_JNvbx6"
      },
      "source": [
        "## Predict wildfire spread from loaded model and plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "HrM2_b88z9G3"
      },
      "outputs": [],
      "source": [
        "# define functions to assess difference between prediction and label\n",
        "\n",
        "# calculate difference\n",
        "def diff_func(pred, act):\n",
        "  act_np = act.numpy().astype(np.int8)\n",
        "  diff_t = np.where(pred != act_np, pred-act_np, pred+act_np)\n",
        "  return diff_t\n",
        "\n",
        "# calculate union\n",
        "def add_func(pred, act):\n",
        "  act_np = act.numpy().astype(np.int8)\n",
        "  add_t = np.where(pred != act_np, pred+act_np, pred*act_np)\n",
        "  return add_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy04wuvostO9"
      },
      "outputs": [],
      "source": [
        "# extract model prediction at varying probability levels\n",
        "upred = unet_model_open.predict(inputs)\n",
        "upredm25 = (upred >= 0.25).astype(np.int8)\n",
        "upredm = (upred >= 0.5).astype(np.int8)\n",
        "upredm75 = (upred >= 0.75).astype(np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "z_werkHXz-Kj"
      },
      "outputs": [],
      "source": [
        "# apply functions to predictions\n",
        "# 50% probability\n",
        "diff_ = diff_func(upredm,labels)\n",
        "add_ = add_func(upredm,labels)\n",
        "# 25% probability\n",
        "diff_25 = diff_func(upredm25,labels)\n",
        "add_25 = add_func(upredm25,labels)\n",
        "# 75% probability\n",
        "diff_75 = diff_func(upredm75,labels)\n",
        "add_75 = add_func(upredm75,labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarise prediction statistics\n",
        "\n",
        "# define output df - 50%\n",
        "output_pred = pd.DataFrame(columns=['row','missed','wrong','correct','score','label'])\n",
        "# write output to df\n",
        "for x in range(0,diff_.shape[0]):\n",
        "  orig = np.sum(labels[x, :, :, 0])\n",
        "  missed = (sum(diff_[x, :, :, 0][diff_[x, :, :, 0]==-1])*-1)\n",
        "  wrong = sum(diff_[x, :, :, 0][diff_[x, :, :, 0]==1])\n",
        "  correct = (sum(diff_[x, :, :, 0][diff_[x, :, :, 0]==2])/2)\n",
        "  score = (correct-(wrong+missed))\n",
        "  output_pred.loc[len(output_pred.index)] = [x, missed, wrong, correct, score, orig]\n",
        "\n",
        "# repeat for 25%\n",
        "output_pred_25 = pd.DataFrame(columns=['row','missed','wrong','correct','score','label'])\n",
        "# write output to df\n",
        "for x in range(0,diff_25.shape[0]):\n",
        "  orig = np.sum(labels[x, :, :, 0])\n",
        "  missed = (sum(diff_25[x, :, :, 0][diff_25[x, :, :, 0]==-1])*-1)\n",
        "  wrong = sum(diff_25[x, :, :, 0][diff_25[x, :, :, 0]==1])\n",
        "  correct = (sum(diff_25[x, :, :, 0][diff_25[x, :, :, 0]==2])/2)\n",
        "  score = (correct-(wrong+missed))\n",
        "  output_pred_25.loc[len(output_pred_25.index)] = [x, missed, wrong, correct, score, orig]\n",
        "\n",
        "# repeat for 75%\n",
        "output_pred_75 = pd.DataFrame(columns=['row','missed','wrong','correct','score','label'])\n",
        "# write output to df\n",
        "for x in range(0,diff_75.shape[0]):\n",
        "  orig = np.sum(labels[x, :, :, 0])\n",
        "  missed = (sum(diff_75[x, :, :, 0][diff_75[x, :, :, 0]==-1])*-1)\n",
        "  wrong = sum(diff_75[x, :, :, 0][diff_75[x, :, :, 0]==1])\n",
        "  correct = (sum(diff_75[x, :, :, 0][diff_75[x, :, :, 0]==2])/2)\n",
        "  score = (correct-(wrong+missed))\n",
        "  output_pred_75.loc[len(output_pred_75.index)] = [x, missed, wrong, correct, score, orig]\n",
        "\n",
        "# write output to csv\n",
        "output_pred.to_csv(os.path.join(savedmodeldir,model_to_load.split(\".\")[0]+\"-runonmodel.csv\"))"
      ],
      "metadata": {
        "id": "aPM57Nl_tg6J"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define sample arrays per data quartile\n",
        "arrayq1 = list(range(1, 500))\n",
        "arrayq2 = list(range(501, 1000))\n",
        "arrayq3 = list(range(1001, 1500))\n",
        "arrayq4 = list(range(1501, 2000))"
      ],
      "metadata": {
        "id": "KV1C4iJNEsNy"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract best/worst match per sample quartile\n",
        "\n",
        "# 50%\n",
        "topfour = [output_pred[output_pred['row'].isin(arrayq1)]['score'].nlargest(n=1).index[0]]\n",
        "topfour.append(output_pred[output_pred['row'].isin(arrayq2)]['score'].nlargest(n=1).index[0])\n",
        "topfour.append(output_pred[output_pred['row'].isin(arrayq3)]['score'].nlargest(n=1).index[0])\n",
        "topfour.append(output_pred[output_pred['row'].isin(arrayq4)]['score'].nlargest(n=1).index[0])\n",
        "botfour = [output_pred[output_pred['row'].isin(arrayq1)]['score'].nsmallest(n=1).index[0]]\n",
        "botfour.append(output_pred[output_pred['row'].isin(arrayq2)]['score'].nsmallest(n=1).index[0])\n",
        "botfour.append(output_pred[output_pred['row'].isin(arrayq3)]['score'].nsmallest(n=1).index[0])\n",
        "botfour.append(output_pred[output_pred['row'].isin(arrayq4)]['score'].nsmallest(n=1).index[0])\n",
        "\n",
        "# 25%\n",
        "topfour25 = [output_pred_25[output_pred_25['row'].isin(arrayq1)]['score'].nlargest(n=1).index[0]]\n",
        "topfour25.append(output_pred_25[output_pred_25['row'].isin(arrayq2)]['score'].nlargest(n=1).index[0])\n",
        "topfour25.append(output_pred_25[output_pred_25['row'].isin(arrayq3)]['score'].nlargest(n=1).index[0])\n",
        "topfour25.append(output_pred_25[output_pred_25['row'].isin(arrayq4)]['score'].nlargest(n=1).index[0])\n",
        "botfour25 = [output_pred_25[output_pred_25['row'].isin(arrayq1)]['score'].nsmallest(n=1).index[0]]\n",
        "botfour25.append(output_pred_25[output_pred_25['row'].isin(arrayq2)]['score'].nsmallest(n=1).index[0])\n",
        "botfour25.append(output_pred_25[output_pred_25['row'].isin(arrayq3)]['score'].nsmallest(n=1).index[0])\n",
        "botfour25.append(output_pred_25[output_pred_25['row'].isin(arrayq4)]['score'].nsmallest(n=1).index[0])\n",
        "\n",
        "# 75%\n",
        "topfour75 = [output_pred_75[output_pred_75['row'].isin(arrayq1)]['score'].nlargest(n=1).index[0]]\n",
        "topfour75.append(output_pred_75[output_pred_75['row'].isin(arrayq2)]['score'].nlargest(n=1).index[0])\n",
        "topfour75.append(output_pred_75[output_pred_75['row'].isin(arrayq3)]['score'].nlargest(n=1).index[0])\n",
        "topfour75.append(output_pred_75[output_pred_75['row'].isin(arrayq4)]['score'].nlargest(n=1).index[0])\n",
        "botfour75 = [output_pred_75[output_pred_75['row'].isin(arrayq1)]['score'].nsmallest(n=1).index[0]]\n",
        "botfour75.append(output_pred_75[output_pred_75['row'].isin(arrayq2)]['score'].nsmallest(n=1).index[0])\n",
        "botfour75.append(output_pred_75[output_pred_75['row'].isin(arrayq3)]['score'].nsmallest(n=1).index[0])\n",
        "botfour75.append(output_pred_75[output_pred_75['row'].isin(arrayq4)]['score'].nsmallest(n=1).index[0])\n",
        "\n",
        "# print identified top/bottom four sampled images\n",
        "print(topfour)\n",
        "print(botfour)"
      ],
      "metadata": {
        "id": "qOTtUlZ755d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot sample of top/bottom four predictions"
      ],
      "metadata": {
        "id": "I1uRYm5DpduZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define datasets from above for plotting\n",
        "predtomap = upredm\n",
        "difftomap = diff_\n",
        "tomaptop = topfour\n",
        "tomapbot = botfour"
      ],
      "metadata": {
        "id": "Zl_Vx7GTI5Sb"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Top 4 Predictions\n",
        "# define tile names\n",
        "TITLES_DIFF = [\n",
        "  'Previous Day Fire', 'Next Day Fire',\n",
        "  'Predicted\\nNext Day Fire', 'Prediction vs Next Day'\n",
        "]\n",
        "\n",
        "# define plot attributes and parameters\n",
        "fig = plt.figure(figsize=(16,12))\n",
        "n_rows = len(tomaptop)\n",
        "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
        "BOUNDS = [-1, -0.1, 0.001, 1]\n",
        "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
        "diff_classes = [-1,-0.01,0.99,1.99,2]\n",
        "diff_colors = ['black', 'silver', 'yellow', 'orangered']\n",
        "diff_cmap = ListedColormap(diff_colors)\n",
        "diff_norm = BoundaryNorm(diff_classes, len(diff_colors))\n",
        "\n",
        "for i in range(n_rows):\n",
        "  k = tomaptop[i]\n",
        "  print(k)\n",
        "  for j in range(4):\n",
        "    plt.subplot(n_rows, 4, i * (4) + j + 1)\n",
        "    if i == 0:\n",
        "      plt.title(TITLES_DIFF[j], fontsize=14)\n",
        "    if j == 0:\n",
        "      plt.imshow(inputs[k, :, :, -1], cmap=CMAP, norm=NORM)\n",
        "    if j == 1:\n",
        "      plt.imshow(labels[k, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == 2:\n",
        "      plt.imshow(predtomap[k, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == 3:\n",
        "      plt.imshow(difftomap[k, :, :, 0], cmap=diff_cmap, norm=diff_norm) \n",
        "    plt.axis('off')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "y485OCICoCrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Bottom 4 Predictions\n",
        "# define tile names\n",
        "TITLES_DIFF = [\n",
        "  'Previous Day Fire', 'Next Day Fire',\n",
        "  'Predicted\\nNext Day Fire', 'Prediction vs Next Day'\n",
        "]\n",
        "\n",
        "# define plot attributes and parameters\n",
        "fig = plt.figure(figsize=(16,12))\n",
        "n_rows = len(tomapbot)\n",
        "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
        "BOUNDS = [-1, -0.1, 0.001, 1]\n",
        "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
        "diff_classes = [-1,-0.01,0.99,1.99,2]\n",
        "diff_colors = ['black', 'silver', 'yellow', 'orangered']\n",
        "diff_cmap = ListedColormap(diff_colors)\n",
        "diff_norm = BoundaryNorm(diff_classes, len(diff_colors))\n",
        "\n",
        "for i in range(n_rows):\n",
        "  k = tomapbot[i]\n",
        "  print(k)\n",
        "  for j in range(4):\n",
        "    plt.subplot(n_rows, 4, i * (4) + j + 1)\n",
        "    if i == 0:\n",
        "      plt.title(TITLES_DIFF[j], fontsize=14)\n",
        "    if j == 0:\n",
        "      plt.imshow(inputs[k, :, :, -1], cmap=CMAP, norm=NORM)\n",
        "    if j == 1:\n",
        "      plt.imshow(labels[k, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == 2:\n",
        "      plt.imshow(predtomap[k, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == 3:\n",
        "      plt.imshow(difftomap[k, :, :, 0], cmap=diff_cmap, norm=diff_norm) \n",
        "    plt.axis('off')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "y8AGwCdlJf5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot sample of predictions with underlying data"
      ],
      "metadata": {
        "id": "SJ4rwnMphFGO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "xrZQq-CRhO6f"
      },
      "outputs": [],
      "source": [
        "# Plot all layers with predictions\n",
        "# define tile names\n",
        "TITLES = ['Elevation', 'Population\\ndensity', 'Urban',\n",
        "          'Drought', 'Precip', 'Energy\\nrelease\\ncomponent', 'Humidity',\n",
        "          'Wind\\ndirection', 'Wind\\nvelocity', 'Wind\\nGust', 'Wind\\nU', 'Wind\\nV',\n",
        "          'Temp', 'NDVI', 'NDII', 'NBR', 'dNBR',\n",
        "          'Previous\\nfire\\nmask', 'Fire\\nmask', 'Fire\\pred', 'Diff']\n",
        "\n",
        "# define plot attributes and parameters\n",
        "addn = 0\n",
        "n_features = inputs.shape[3]\n",
        "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
        "CMAP_DIFF = colors.ListedColormap(['black', 'silver', 'yellow', 'orangered'])\n",
        "BOUNDS = [-1, -0.1, 0.001, 1]\n",
        "BOUNDS_DIFF = [-1, -0.01, 0.01, 0.99, 1.01, 1.99,  2]\n",
        "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
        "NORM_DIFF = colors.BoundaryNorm(BOUNDS_DIFF, CMAP_DIFF.N)\n",
        "NORM_V = colors.NoNorm(vmin=0, vmax=1)\n",
        "diff_classes = [-1,-0.01,0.99,1.99,2]\n",
        "diff_colors = ['black', 'silver', 'yellow', 'orangered']\n",
        "diff_cmap = ListedColormap(diff_colors)\n",
        "diff_norm = BoundaryNorm(diff_classes, len(diff_colors))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot random sample for top four\n",
        "fig = plt.figure(figsize=(24,8))\n",
        "\n",
        "n_rows = len(tomaptop)\n",
        "\n",
        "for i in range(n_rows):\n",
        "  k = tomaptop[i]\n",
        "  for j in range(n_features + 3):\n",
        "    plt.subplot(n_rows, n_features + 3, i * (n_features + 3) + j + 1)\n",
        "    if i == 0:\n",
        "      plt.title(TITLES[j], fontsize=13)\n",
        "    if j < n_features - 1:\n",
        "      plt.imshow(inputs[k+addn, :, :, j], cmap='viridis')\n",
        "    if j == n_features - 1:\n",
        "      plt.imshow(inputs[k+addn, :, :, -1], cmap=CMAP, norm=NORM)\n",
        "    if j == n_features:\n",
        "      plt.imshow(labels[k+addn, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == n_features + 1:\n",
        "      plt.imshow(upredm[k+addn, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == n_features + 2:\n",
        "      plt.imshow(diff_[k+addn, :, :, 0], cmap=diff_cmap, norm=diff_norm) \n",
        "    plt.axis('off')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "f3KNc4aEo1GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv8di20ro3V6"
      },
      "outputs": [],
      "source": [
        "# plot random sample for bottom four\n",
        "fig = plt.figure(figsize=(24,8))\n",
        "\n",
        "n_rows = len(tomapbot)\n",
        "\n",
        "for i in range(n_rows):\n",
        "  k = tomapbot[i]\n",
        "  for j in range(n_features + 3):\n",
        "    plt.subplot(n_rows, n_features + 3, i * (n_features + 3) + j + 1)\n",
        "    if i == 0:\n",
        "      plt.title(TITLES[j], fontsize=13)\n",
        "    if j < n_features - 1:\n",
        "      plt.imshow(inputs[k+addn, :, :, j], cmap='viridis')\n",
        "    if j == n_features - 1:\n",
        "      plt.imshow(inputs[k+addn, :, :, -1], cmap=CMAP, norm=NORM)\n",
        "    if j == n_features:\n",
        "      plt.imshow(labels[k+addn, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == n_features + 1:\n",
        "      plt.imshow(upredm[k+addn, :, :, 0], cmap=CMAP, norm=NORM) \n",
        "    if j == n_features + 2:\n",
        "      plt.imshow(diff_[k+addn, :, :, 0], cmap=diff_cmap, norm=diff_norm) \n",
        "    plt.axis('off')\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JfXx6iplUP8V",
        "A4r16-4MVGd9",
        "Z__EqbLqWPuT",
        "aq4UVk6v5qZQ",
        "9uEkWDq9cxsi",
        "cazaDCsphxCw",
        "311IhFgAXuLK",
        "QuJ8YGLP2Kxk",
        "ZrSN7Ooy7po4",
        "a8d62HZLhvdz",
        "loCr0TrueFZt",
        "8KrgPeRTA1us",
        "sDgdi2ZSA7rt",
        "M75_ERkwBABl",
        "PZBEN7aaGrDe",
        "RI8QujVuhptU",
        "hGhJkeH-jq4-",
        "kGIaQsqyNkBP",
        "HstRZ_JNvbx6",
        "I1uRYm5DpduZ",
        "SJ4rwnMphFGO"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMbHcCo4Xh6o1Zou9UZ2i9s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}